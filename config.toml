[llm]
client_type = "ollama"
model_type = "llama3.1"
max_tokens = 1000
host = "http://127.0.0.1:11434"
