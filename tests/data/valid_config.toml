[llm]
client_type = "ollama"
model_type = "llama3.1"
max_tokens = 1000
